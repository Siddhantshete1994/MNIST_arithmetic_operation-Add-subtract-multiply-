{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9b6b26d1",
   "metadata": {},
   "source": [
    "This code cell performs all the steps above with 1,000 samples per permutation pair and trains the network over 100 epochs, using a 10 fold cross validation, in one go. Therefore, this will take a long time to execute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a52bbce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_pairs = [str(x)+str(y) for x in range(10) for y in range(10)]\n",
    "train_counter = 0\n",
    "\n",
    "(X_train_keras, y_train_keras), (X_test_keras, y_test_keras) = mnist.load_data()\n",
    "\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=376483)\n",
    "kf.get_n_splits(unique_pairs)\n",
    "\n",
    "unique_pairs_np = np.asarray(unique_pairs)\n",
    "# Store network performance history and score for each of the training runs.\n",
    "histories = []\n",
    "scores = []\n",
    "\n",
    "# Store accuracies measured in various ways\n",
    "accuracies_rounded = []\n",
    "accuracies_floor_ceil = []\n",
    "accuracies_leeway = []\n",
    "\n",
    "\n",
    "for train_index, test_index in kf.split(unique_pairs):\n",
    "    test_set_pairs = unique_pairs_np[test_index]\n",
    "    train_set_pairs = unique_pairs_np[train_index]\n",
    "    \n",
    "    # Sanity checks\n",
    "    assert(len(test_set_pairs) == 10)\n",
    "    assert(len(train_set_pairs) == 90)\n",
    "    for test_set_pair in test_set_pairs:\n",
    "        assert(test_set_pair not in train_set_pairs)\n",
    "    \n",
    "    # If these pass we are good to go with data generation\n",
    "    X_train = []\n",
    "    y_train = []\n",
    "\n",
    "    # Number of samples per permutation (e.g. there are 90 permutations in the train \n",
    "    # set so 1000*90 makes 90,000 training samples and 10*1000=10,000 test samples)\n",
    "    samples_per_permutation = 1000  \n",
    "\n",
    "    for train_set_pair in train_set_pairs:\n",
    "        for _ in range(samples_per_permutation):\n",
    "            rand_i = np.random.choice(np.where(y_train_keras == int(train_set_pair[0]))[0])\n",
    "            rand_j = np.random.choice(np.where(y_train_keras == int(train_set_pair[1]))[0])\n",
    "        \n",
    "            temp_image = np.zeros((28,56), dtype=\"uint8\")\n",
    "            temp_image[:,:28] = X_train_keras[rand_i]\n",
    "            temp_image[:,28:] = X_train_keras[rand_j]\n",
    "\n",
    "            X_train.append(temp_image)\n",
    "            y_train.append(y_train_keras[rand_i] + y_train_keras[rand_j])\n",
    "        \n",
    "    X_test = []\n",
    "    y_test = []\n",
    "    \n",
    "    for test_set_pair in test_set_pairs:\n",
    "        for _ in range(samples_per_permutation):\n",
    "            rand_i = np.random.choice(np.where(y_test_keras == int(test_set_pair[0]))[0])\n",
    "            rand_j = np.random.choice(np.where(y_test_keras == int(test_set_pair[1]))[0])\n",
    "        \n",
    "            temp_image = np.zeros((28,56), dtype=\"uint8\")\n",
    "            temp_image[:,:28] = X_test_keras[rand_i]\n",
    "            temp_image[:,28:] = X_test_keras[rand_j]\n",
    "            \n",
    "            X_test.append(temp_image)\n",
    "            y_test.append(y_test_keras[rand_i] + y_test_keras[rand_j])\n",
    "    \n",
    "    \n",
    "    X_train = np.asarray(X_train)\n",
    "    y_train = np.asarray(y_train)\n",
    "    X_test = np.asarray(X_test)\n",
    "    y_test = np.asarray(y_test)\n",
    "\n",
    "    X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], X_train.shape[2], 1)\n",
    "    X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], X_test.shape[2], 1)\n",
    "    \n",
    "    # Some standard preprocessing things here.\n",
    "    # Reformat the images to use floating point values rather than integers between 0-255\n",
    "    X_train = X_train.astype('float32')\n",
    "    X_test = X_test.astype('float32')\n",
    "    X_train /= 255\n",
    "    X_test /= 255\n",
    "    \n",
    "    # Shuffling\n",
    "    X_train, y_train = utils.shuffle(X_train, y_train)\n",
    "    X_test, y_test = utils.shuffle(X_test, y_test)\n",
    "    \n",
    "    ######################################################\n",
    "    # NETWORK SETUP AND TRAINING\n",
    "    ######################################################\n",
    "    batch_size = 128\n",
    "    num_classes = 1               \n",
    "    epochs = 100\n",
    "    img_rows, img_cols = np.shape(X_train)[1], np.shape(X_train)[2]\n",
    "    input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "    ######################################################\n",
    "    # Set up the network model\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                     activation='relu',\n",
    "                     input_shape=input_shape))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))  # Default is (3, 3)\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2))) \n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(256, activation='relu'))  # Default is 128\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    # Do not use softmax here, just specify one nueron\n",
    "    model.add(Dense(num_classes)) \n",
    "\n",
    "    ######################################################\n",
    "    # Choose an optimiser.\n",
    "    rms = optimizers.RMSprop(lr=0.001, rho=0.9, epsilon=1e-08, decay=0.0)\n",
    "    sgd = optimizers.SGD(lr=0.0001, decay=1e-5, momentum=0.9, nesterov=True)\n",
    "    ada = optimizers.Adadelta(lr=1.0, rho=0.95, epsilon=1e-08, decay=0.0)\n",
    "    ndm = optimizers.Nadam(lr=0.002, beta_1=0.9, beta_2=0.999, epsilon=1e-08, schedule_decay=0.004)\n",
    "\n",
    "    ######################################################\n",
    "    # Note: As this is a regression problem, use only mean squared error \n",
    "    # or mean absolute error as loss.\n",
    "    model.compile(loss=losses.mean_squared_error, optimizer=ada)\n",
    "    \n",
    "    ## LET'S TRAIN\n",
    "    histories.append(model.fit(X_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    validation_data=(X_test, y_test),\n",
    "                    verbose=0))\n",
    "    \n",
    "    print(\"RUN %s\" % train_counter)\n",
    "    \n",
    "    scores.append(model.evaluate(X_test, y_test, verbose=0))\n",
    "    print(model.evaluate(X_test, y_test, verbose=1))\n",
    "    \n",
    "    rounded_correct = 0\n",
    "    rounded_incorrect = 0\n",
    "    floor_ceil_correct = 0\n",
    "    floor_ceil_incorrect = 0\n",
    "    leeway_correct = 0\n",
    "    leeway_incorrect = 0\n",
    "\n",
    "    for i in range(0, len(y_test)):\n",
    "        prediction = model.predict(X_test[i].reshape(1, X_test[i].shape[0], X_test[i].shape[1], 1))[0][0]\n",
    "\n",
    "        rounded_prediction = round(prediction)\n",
    "        floor_prediction = floor(prediction)\n",
    "        ceiling_prediction = ceil(prediction)\n",
    "\n",
    "        # Rounded to the nearest integer\n",
    "        if rounded_prediction == y_test[i]:\n",
    "            rounded_correct += 1\n",
    "        else:\n",
    "            rounded_incorrect += 1\n",
    "\n",
    "        # Floor or ceiling\n",
    "        if (floor_prediction == y_test[i]) or (ceiling_prediction == y_test[i]):\n",
    "            floor_ceil_correct += 1\n",
    "        else:\n",
    "            floor_ceil_incorrect += 1\n",
    "\n",
    "        # Leeway of 1\n",
    "        abs_difference = abs(rounded_prediction-y_test[i])\n",
    "\n",
    "        if abs_difference <= 1:\n",
    "            leeway_correct += 1\n",
    "        else:\n",
    "            leeway_incorrect += 1\n",
    "\n",
    "    accuracies_rounded.append((rounded_correct, rounded_incorrect))\n",
    "    accuracies_floor_ceil.append((floor_ceil_correct, floor_ceil_incorrect))\n",
    "    accuracies_leeway.append((leeway_correct, leeway_incorrect))\n",
    "\n",
    "    print(\"Correct (rounded): %s, Incorrect (rounded): %s\" % (rounded_correct, rounded_incorrect))        \n",
    "    print(\"Correct (floor/ceiling): %s, Incorrect (floor/ceiling): %s\" % (floor_ceil_correct, floor_ceil_incorrect))\n",
    "    print(\"Correct (leeway): %s, Incorrect (leeway): %s\" % (leeway_correct, leeway_incorrect))\n",
    "    \n",
    "    print(\"END %s\\n\" % train_counter)\n",
    "    \n",
    "    train_counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "190fb968",
   "metadata": {},
   "outputs": [],
   "source": [
    "for history in histories:\n",
    "    print(\"Train loss: %s Test loss: %s\" % (history.history[\"loss\"][-1], history.history[\"val_loss\"][-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43629cbc",
   "metadata": {},
   "source": [
    "The losses over all epochs plotted for each of the train/test splits in the 10-fold cross validation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "404a285e",
   "metadata": {},
   "outputs": [],
   "source": [
    "h_counter = 1\n",
    "for history in histories:\n",
    "    score = history.history['val_loss'][-1]\n",
    "    plt.xlim(0,len(history.history['loss'])-1)\n",
    "    plt.plot(history.history['loss'], linestyle='--', linewidth=3)\n",
    "    plt.plot(history.history['val_loss'], linewidth=3)\n",
    "    plt.title('Loss on Test/Training Set, Split %s' % h_counter)\n",
    "    plt.ylabel('Loss (MSE)')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Training Set', 'Test Set (Loss @ Final Epoch: '+ str(\"%.2f\"%score) +')'], loc='upper right')\n",
    "    #plt.savefig(\"/tmp/loss-100-epochs-%s-fold.pdf\" % h_counter)\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    h_counter += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
